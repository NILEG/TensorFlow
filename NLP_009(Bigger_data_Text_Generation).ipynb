{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNSLK9LEr2cEHle4+PFPYPA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NILEG/TensorFlow/blob/main/NLP_009(Bigger_data_Text_Generation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DSVkX3IvoIFj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 15UqmiIm0xwh9mt0IYq2z3jHaauxQSTQT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg98g_wIoXkP",
        "outputId": "a609e5e0-e861-445e-cd21-abe77ce0f28c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15UqmiIm0xwh9mt0IYq2z3jHaauxQSTQT\n",
            "To: /content/irish-lyrics-eof.txt\n",
            "100% 69.0k/69.0k [00:00<00:00, 140MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file=open(\"irish-lyrics-eof.txt\")\n",
        "data=file.read().lower().split(\"\\n\")\n",
        "print(data[:10])"
      ],
      "metadata": {
        "id": "Ie-gGAFWobq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(data)"
      ],
      "metadata": {
        "id": "fTWbVVzSo8vm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[]\n",
        "for line in data:\n",
        "  sequence=tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(sequence)):\n",
        "    sentences.append(sequence[:i+1])\n",
        "sentences[:10]"
      ],
      "metadata": {
        "id": "gEcppXQTpRTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words=len(tokenizer.word_index)+1\n",
        "max_len=max([len(x) for x in sentences])\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPf5dmKvpwH9",
        "outputId": "8f2a6c58-e2ef-4046-ddc3-271c962cdd44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad_sentences=tf.keras.preprocessing.sequence.pad_sequences(sentences, maxlen=max_len, padding=\"pre\")\n",
        "training_data=np.array(pad_sentences[:,:-1], dtype=np.float32)\n",
        "labels=np.array(pad_sentences[:,-1], dtype=np.float32)\n",
        "labels[:10]"
      ],
      "metadata": {
        "id": "1geqOCKJp7uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([tf.keras.layers.Input(shape=(max_len-1, )),\n",
        "                           tf.keras.layers.Embedding(total_words, 100),\n",
        "                           tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
        "                           tf.keras.layers.Dense(total_words, activation=\"softmax\")])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2TVgLNyqZt8",
        "outputId": "2de4dbf7-9998-4d3d-e67e-8ae426745b2b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 15, 100)           269000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 300)               301200    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2690)              809690    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1379890 (5.26 MB)\n",
            "Trainable params: 1379890 (5.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(training_data, labels, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrvddOX0rmBL",
        "outputId": "7cf9bf7f-4c99-408a-9da4-f97285a23b3a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "377/377 [==============================] - 22s 34ms/step - loss: 6.7621 - accuracy: 0.0640\n",
            "Epoch 2/100\n",
            "377/377 [==============================] - 5s 12ms/step - loss: 6.2306 - accuracy: 0.0751\n",
            "Epoch 3/100\n",
            "377/377 [==============================] - 4s 9ms/step - loss: 5.9514 - accuracy: 0.0835\n",
            "Epoch 4/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 5.6463 - accuracy: 0.0994\n",
            "Epoch 5/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 5.2994 - accuracy: 0.1167\n",
            "Epoch 6/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 4.9313 - accuracy: 0.1373\n",
            "Epoch 7/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 4.5560 - accuracy: 0.1589\n",
            "Epoch 8/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 4.1961 - accuracy: 0.1867\n",
            "Epoch 9/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 3.8545 - accuracy: 0.2228\n",
            "Epoch 10/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 3.5243 - accuracy: 0.2711\n",
            "Epoch 11/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 3.2253 - accuracy: 0.3214\n",
            "Epoch 12/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 2.9440 - accuracy: 0.3741\n",
            "Epoch 13/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 2.6778 - accuracy: 0.4271\n",
            "Epoch 14/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 2.4487 - accuracy: 0.4721\n",
            "Epoch 15/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 2.2351 - accuracy: 0.5180\n",
            "Epoch 16/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 2.0554 - accuracy: 0.5566\n",
            "Epoch 17/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 1.8794 - accuracy: 0.5940\n",
            "Epoch 18/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 1.7259 - accuracy: 0.6338\n",
            "Epoch 19/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 1.5975 - accuracy: 0.6535\n",
            "Epoch 20/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 1.4727 - accuracy: 0.6810\n",
            "Epoch 21/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 1.3533 - accuracy: 0.7130\n",
            "Epoch 22/100\n",
            "377/377 [==============================] - 6s 15ms/step - loss: 1.2586 - accuracy: 0.7335\n",
            "Epoch 23/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 1.1672 - accuracy: 0.7535\n",
            "Epoch 24/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 1.0867 - accuracy: 0.7713\n",
            "Epoch 25/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 1.0138 - accuracy: 0.7833\n",
            "Epoch 26/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.9541 - accuracy: 0.7984\n",
            "Epoch 27/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.8991 - accuracy: 0.8080\n",
            "Epoch 28/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.8509 - accuracy: 0.8162\n",
            "Epoch 29/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.8033 - accuracy: 0.8243\n",
            "Epoch 30/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.7690 - accuracy: 0.8301\n",
            "Epoch 31/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.7437 - accuracy: 0.8346\n",
            "Epoch 32/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.7109 - accuracy: 0.8378\n",
            "Epoch 33/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.6939 - accuracy: 0.8391\n",
            "Epoch 34/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.6628 - accuracy: 0.8437\n",
            "Epoch 35/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.6511 - accuracy: 0.8453\n",
            "Epoch 36/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.6331 - accuracy: 0.8481\n",
            "Epoch 37/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.6166 - accuracy: 0.8479\n",
            "Epoch 38/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.6151 - accuracy: 0.8472\n",
            "Epoch 39/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.6057 - accuracy: 0.8469\n",
            "Epoch 40/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5859 - accuracy: 0.8506\n",
            "Epoch 41/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5812 - accuracy: 0.8495\n",
            "Epoch 42/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.5757 - accuracy: 0.8512\n",
            "Epoch 43/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.5710 - accuracy: 0.8506\n",
            "Epoch 44/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5636 - accuracy: 0.8498\n",
            "Epoch 45/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5586 - accuracy: 0.8496\n",
            "Epoch 46/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5557 - accuracy: 0.8496\n",
            "Epoch 47/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.5487 - accuracy: 0.8506\n",
            "Epoch 48/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5417 - accuracy: 0.8516\n",
            "Epoch 49/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5418 - accuracy: 0.8512\n",
            "Epoch 50/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5409 - accuracy: 0.8515\n",
            "Epoch 51/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.5443 - accuracy: 0.8508\n",
            "Epoch 52/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5335 - accuracy: 0.8509\n",
            "Epoch 53/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5325 - accuracy: 0.8506\n",
            "Epoch 54/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5294 - accuracy: 0.8498\n",
            "Epoch 55/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5221 - accuracy: 0.8523\n",
            "Epoch 56/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.5195 - accuracy: 0.8526\n",
            "Epoch 57/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5211 - accuracy: 0.8516\n",
            "Epoch 58/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5185 - accuracy: 0.8525\n",
            "Epoch 59/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.5194 - accuracy: 0.8517\n",
            "Epoch 60/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.5171 - accuracy: 0.8521\n",
            "Epoch 61/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5163 - accuracy: 0.8515\n",
            "Epoch 62/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5104 - accuracy: 0.8522\n",
            "Epoch 63/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5080 - accuracy: 0.8519\n",
            "Epoch 64/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.5071 - accuracy: 0.8526\n",
            "Epoch 65/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.5072 - accuracy: 0.8535\n",
            "Epoch 66/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5063 - accuracy: 0.8510\n",
            "Epoch 67/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5038 - accuracy: 0.8530\n",
            "Epoch 68/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5068 - accuracy: 0.8525\n",
            "Epoch 69/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.5038 - accuracy: 0.8512\n",
            "Epoch 70/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.5000 - accuracy: 0.8533\n",
            "Epoch 71/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4984 - accuracy: 0.8526\n",
            "Epoch 72/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4982 - accuracy: 0.8528\n",
            "Epoch 73/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.4940 - accuracy: 0.8518\n",
            "Epoch 74/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4944 - accuracy: 0.8523\n",
            "Epoch 75/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4921 - accuracy: 0.8513\n",
            "Epoch 76/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4932 - accuracy: 0.8522\n",
            "Epoch 77/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4927 - accuracy: 0.8533\n",
            "Epoch 78/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.4916 - accuracy: 0.8532\n",
            "Epoch 79/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4912 - accuracy: 0.8532\n",
            "Epoch 80/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4885 - accuracy: 0.8529\n",
            "Epoch 81/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4880 - accuracy: 0.8535\n",
            "Epoch 82/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.4877 - accuracy: 0.8506\n",
            "Epoch 83/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4850 - accuracy: 0.8537\n",
            "Epoch 84/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4850 - accuracy: 0.8521\n",
            "Epoch 85/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4815 - accuracy: 0.8540\n",
            "Epoch 86/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4840 - accuracy: 0.8520\n",
            "Epoch 87/100\n",
            "377/377 [==============================] - 3s 9ms/step - loss: 0.4841 - accuracy: 0.8531\n",
            "Epoch 88/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4879 - accuracy: 0.8535\n",
            "Epoch 89/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4824 - accuracy: 0.8545\n",
            "Epoch 90/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4827 - accuracy: 0.8516\n",
            "Epoch 91/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.4781 - accuracy: 0.8533\n",
            "Epoch 92/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4769 - accuracy: 0.8538\n",
            "Epoch 93/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4769 - accuracy: 0.8523\n",
            "Epoch 94/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4751 - accuracy: 0.8561\n",
            "Epoch 95/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4758 - accuracy: 0.8540\n",
            "Epoch 96/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.4776 - accuracy: 0.8516\n",
            "Epoch 97/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4753 - accuracy: 0.8557\n",
            "Epoch 98/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4784 - accuracy: 0.8521\n",
            "Epoch 99/100\n",
            "377/377 [==============================] - 3s 7ms/step - loss: 0.4821 - accuracy: 0.8537\n",
            "Epoch 100/100\n",
            "377/377 [==============================] - 3s 8ms/step - loss: 0.4797 - accuracy: 0.8520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Highest Probability"
      ],
      "metadata": {
        "id": "567PKMr43M1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text=\"help me obi-wan kinobi youre my only hope\"\n",
        "seed_size=100\n",
        "for i in range(seed_size):\n",
        "  sequence=tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  pad_sequence=tf.keras.preprocessing.sequence.pad_sequences([sequence], maxlen=max_len-1, padding=\"pre\")\n",
        "  probabilities=model.predict(pad_sequence, verbose=0)\n",
        "  index=np.argmax(probabilities, axis=-1)[0]\n",
        "  if(index !=0):\n",
        "    word=tokenizer.index_word[index]\n",
        "    seed_text=seed_text+\" \"+word\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yLqTKvert-p",
        "outputId": "0663b324-e1c2-4284-b054-8cdb05f1f0c9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "help me obi-wan kinobi youre my only hope our more round our day day well more return nor laws leg smiling chop struggle souls to the fairy way to dublin true true can play the foemans did he stand he crew say you fell on the sod then i had had had a fine summers day had a jewel of skibbereen had a bishop time had had had had had sinking sinking island dove sinking guff bubblin bubblin stone fray rakes sea gesture rakes meadow pipes dawning paddys twas for the tree tree the broad down are down and down out by mooncoin town down down to glen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Random Prediction from top 3 highest probabilities"
      ],
      "metadata": {
        "id": "rqFZVC9a3F32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text=\"help me obi-wan kinobi youre my only hope\"\n",
        "seed_size=100\n",
        "for i in range(seed_size):\n",
        "  sequence=tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  pad_sequence=tf.keras.preprocessing.sequence.pad_sequences([sequence], maxlen=max_len-1, padding=\"pre\")\n",
        "  probabilities=model.predict(pad_sequence, verbose=0)\n",
        "\n",
        "  choice=np.random.choice([1,2,3])\n",
        "\n",
        "  index=np.argsort(probabilities)[0][-choice]\n",
        "  if(index !=0):\n",
        "    word=tokenizer.index_word[index]\n",
        "    seed_text=seed_text+\" \"+word\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bijmG6fK1V1-",
        "outputId": "4e329e2e-595a-4a0d-b39c-49ebb8b79975"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "help me obi-wan kinobi youre my only hope more turn for her more dear night return up in spirit her done for tralee away behind an fingers tree flower the rocky o rocky bells chop ill not could around the sod im be in fray skibbereen grow on your ground crossed gilgarra sea her fathers loo fondly sea thought day an day began to thought cant clergy dear fair sons sea vow morn be able nothing find primrose cant smoke thee sword on your banks and the bold theres a tear in your eye eyes ever ever down by mooncoin return by down again down to old her\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQxO_0Uc3bHG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}